---
title: "Assignment 3"
author: "Lucas Ho"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
header-includes:
  - \usepackage{booktabs}
  - \usepackage{amsmath}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\[
16/16
\]

# Question 1
## Part a
$$
P(Y > 120) = \int_{120}^{\infty} \frac{e^{-\frac{y}{95}}}{95} \, dy = -e^{-\frac{y}{95}} \Bigg|_{120}^{\infty} = -e^{-\frac{\infty}{95}} + e^{-\frac{120}{95}} = 0 + 0.28276 = 0.28276
$$

# Question 2
## Part a
\[
\mu = \alpha\beta = 3(0.07) = 0.21
\]

\[
\sigma^2 = \alpha\beta^2 = 3(0.07)^2 = 0.0147
\]

## Part b
\[
\sigma = \sqrt{\sigma^2} = \sqrt{0.0147} = 0.1212
\]

\[
\mu \pm 3\sigma \Rightarrow 0.21 \pm 3(0.1212) \Rightarrow 0.21 \pm 0.3636 \Rightarrow (-0.1536, 0.5736)
\]


The gamma distribution with $\alpha$ = 3 and $\beta$ = 0.07 does not have strong evidence to model the behavior since 0.60 falls outside the range.

# Question 3
## Part a
\[
\mu_A = \alpha\beta = 2(2) = 4; \quad \mu_B = \alpha\beta = 1(4) = 4
\]

## Part b
\[
\sigma^2_A = \alpha\beta^2 = 2(2)^2 = 8; \quad \sigma^2_B = \alpha\beta^2 = 1(4)^2 = 16
\]

## Part c
For part a
\[
P(Y \leq 1) = \int_{0}^{1} \frac{y^{2-1} e^{-y/2}}{2^{2} \Gamma(2)} \, dy = \int_{0}^{1} \frac{y e^{-y/2}}{4} \, dy = \left[ -\left( \frac{2y e^{-y/2}}{4} \right) \right]_{0}^{1} + \left[ \frac{1}{4} \int_{0}^{1} 2e^{-y/2} \, dy \right]
\]
\[
= \frac{1}{4} \left( -2e^{-1/2} + 2(0) e^{0} \right) + \left( -e^{-y/2} \right)_{0}^{1}
\]
\[
= -0.3033 - e^{-1/2} + e^{0} = 0.0902
\]
For part b
\[
P(Y \leq 1) = \int_{0}^{1} \frac{y^{1-1} e^{-y/4}}{4 \Gamma(1)} \, dy = \int_{0}^{1} \frac{e^{-y/4}}{4} \, dy = \left[ -e^{-y/4} \right]_{0}^{1}
\]
\[
= -e^{-1/4} + e^{0} = 1 - 0.7788 = 0.2212
\]
Formula B has a higher probability of generating a human reaction in less than 1 minute.

# Question 4
## Part a
\[
F(y) = 1 - e^{-y^\frac{1}{\beta}}
\]
\[
P(Y \geq 2) = F(2) = 1 - e^{-2^\frac{1}{4}} = 1 - e^{-2^\frac{1}{2}} = 1 - 0.36788 = 0.63212
\]
## Part b
\[
\mu = \beta^\alpha \Gamma \left( \frac{\alpha + 1}{\alpha} \right) = 4^{1/2} \Gamma \left( \frac{2 + 1}{2} \right) = 2\Gamma(1.5) = 2(0.88623) = 1.77246
\]

\[
\sigma^2 = \beta^2 \left[ \Gamma \left( \frac{\alpha + 2}{\alpha} \right) - \Gamma^2 \left( \frac{\alpha + 1}{\alpha} \right) \right] = 4^{2/2} \left[ \Gamma \left( \frac{2 + 2}{2} \right) - \Gamma^2 \left( \frac{2 + 1}{2} \right) \right] = 4 \left[ \Gamma(2) - \Gamma^2(1.5) \right] = 4(1 - 0.88623^2)
\]
\[
= 4(1 - 0.7854) = 0.8584
\]

\[
\sigma = \sqrt{0.8584} = 0.9265
\]
## Part c
\[
\mu \pm 2\sigma \Rightarrow 1.77246 \pm 2(0.9265) \Rightarrow 1.77246 \pm 1.853 \Rightarrow (-0.08054, 3.62546)
\]

From Example 5.15, 
\[
F(y) = 1 - e^{-y^{1/\beta}}
\]

\[
P(-0.08054 < Y < 3.62546) = F(3.62546) - F(0) = \left( 1 - e^{-3.62546^{1/4}} \right) - \left( 1 - e^{-0^{1/4}} \right)
\]
\[
= \left( 1 - e^{-3.286} \right) - (1 - 1) = 1 - 0.0374 = 0.9626
\]

## Part d
No. $P(Y > 6) = 1 - P(Y \leq 6) = 1 - F(6) = 1 - \left( 1 - e^{-6^2/4} \right) = e^{-9} = 0.0001234.$ This probability is quite small.

# Question 5
## Part a
\[
E(Y) = \mu = \frac{\alpha}{\alpha + \beta} = \frac{2}{2 + 9} = \frac{2}{11} = 0.18182
\]

\[
\sigma^2 = \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)} = \frac{2 \cdot 9}{(2 + 9)^2(2 + 9 + 1)} = \frac{18}{(11)^2(12)} = 0.01240
\]

## Part b
For $n = (\alpha + \beta - 1) = 2 + 9 - 1 = 10, p = 0.40,$ $P(Y > 0.40) = 1 - P(Y \leq 0.40) = 1 - F(0.40) = 1 - \sum_{y=2}^{10} p(y) = \sum_{y=0}^{1} p(y) = 0.0464$

## Part c
For $n = (\alpha + \beta - 1) = 2 + 9 - 1 = 10, \, p = 0.10$

\[
P(Y \leq 0.10) = F(0.10) = \sum_{y=2}^{10} p(y) = 1 - \sum_{y=0}^{1} p(y) = 1 - 0.7361 = 0.2639
\]

# Question 5
## Part a
$\alpha = 2$ and $\beta = 16$

## Part b
\[
\mu = \beta^\alpha \Gamma \left( \frac{\alpha + 1}{\alpha} \right) = 16^{1/2} \Gamma \left( \frac{2 + 1}{2} \right) = 4\Gamma(1.5) = 4(0.88623) = 3.545
\]

\[
\sigma^2 = \beta^{2/\alpha} \left[ \Gamma \left( \frac{\alpha + 2}{\alpha} \right) - \Gamma^2 \left( \frac{\alpha + 1}{\alpha} \right) \right] = 16^{2/2} \left[ \Gamma \left( \frac{2 + 2}{2} \right) - \Gamma^2 \left( \frac{2 + 1}{2} \right) \right] = 16 \left[ \Gamma(2) - \Gamma^2(1.5) \right]
\]
\[
= 16(1 - 0.88623^2) = 16(0.214596) = 3.4335
\]

## Part c
\[
P(Y \geq 6) = 1 - P(Y < 6) = 1 - F(6) = 1 - \left[ 1 - e^{-\left(6^\frac{1}{\beta}\right)} \right] = 1 - \left[ 1 - e^{-\left(6^\frac{1}{8}\right)} \right]
\]
\[
= 1 - \left[ 1 - e^{-\left(6^\frac{1}{16}\right)} \right] = 1 - 0.8946 = 0.1054
\]

# Question 6
## Part a
We know \( 1 \leq X \leq 6 \) and \( 1 \leq Y \leq 6 \). Each of the 36 outcomes is equally likely, so
\[
p(x, y) = \frac{1}{36} \quad 1 \leq x \leq 6, 1 \leq y \leq 6.
\]

## Part b
\[
P(X = 1) = p_1(1) = p(1,1) + p(1,2) + p(1,3) + p(1,4) + p(1,5) + p(1,6)
\]
\[
= \frac{1}{36} + \frac{1}{36} + \frac{1}{36} + \frac{1}{36} + \frac{1}{36} + \frac{1}{36} = \frac{6}{36} = \frac{1}{6}
\]

Similarly,
\[
p_1(2) = p_1(3) = \cdots = p_1(6) = \frac{1}{6}
\]

## Part c
When \( y = 1 \), \( p_1(x | 1) = \frac{p(x, 1)}{p_2(1)} \)

\[
p_1(1 | 1) = \frac{p(1,1)}{p_2(1)} = \frac{\frac{1}{36}}{\frac{1}{6}} = \frac{1}{6}
\]
\[
p_1(2 | 1) = \frac{p(2,1)}{p_2(1)} = \frac{\frac{1}{36}}{\frac{1}{6}} = \frac{1}{6}
\]
\[
\cdots
\]
\[
p_1(6 | 1) = \frac{p(6,1)}{p_2(1)} = \frac{\frac{1}{36}}{\frac{1}{6}} = \frac{1}{6}
\]

In fact,
\[
p_1(x | y) = \frac{p(x, y)}{p_2(y)} = \frac{1}{6} \quad \text{for } 1 \leq x \leq 6, 1 \leq y \leq 6
\]
\[
\text{and} \quad p_2(y | x) = \frac{p(x, y)}{p_1(x)} = \frac{1}{6} \quad \text{for } 1 \leq x \leq 6, 1 \leq y \leq 6
\]

## Part a
The bivariate probability distribution \( p(x, y) \) in table form is:
```{r}
library(knitr)

# Create a data frame for the table contents
prob_distribution <- data.frame(
  ` ` = c(1, 2, 3),
  `1` = c(1/7, 0, 0),
  `2` = c(2/7, 0, 0),
  `3` = c(1/7, 2/7, 1/7)
)
rownames(prob_distribution) <- c(1, 2, 3)

# Print the table
knitr::kable(prob_distribution, col.names = c("y\\x", "1", "2", "3"), align = 'c')
```
## Part b
\[
P(X = 1) = p_1(1) = p(1,1) + p(1,2) + p(1,3) = \frac{1}{7} + 0 + 0 = \frac{1}{7}
\]

\[
P(X = 2) = p_1(2) = p(2,1) + p(2,2) + p(2,3) = \frac{2}{7} + 0 + 0 = \frac{2}{7}
\]

\[
P(X = 3) = p_1(3) = p(3,1) + p(3,2) + p(3,3) = \frac{1}{7} + \frac{2}{7} + \frac{1}{7} = \frac{4}{7}
\]

In table form, the marginal probability distribution \( p_1(x) \) is:
```{r}
library(knitr)

# Manually create the table to display it with kable
probability_table <- rbind(
  c("1/7", "2/7", "1/7"),
  c("0", "0", "2/7"),
  c("0", "0", "1/7")
)

colnames(probability_table) <- c("1", "2", "3")
rownames(probability_table) <- c("1", "2", "3")

kable(probability_table, caption = "The marginal probability distribution")
```

## Part c
```{r}
# Create a matrix for the table contents
prob_matrix <- matrix(
  c(4/7, 2/7, 1/7),
  nrow = 1, byrow = TRUE
)

# Add column names for the table header
colnames(prob_matrix) <- c("1", "2", "3")

# Create a table with knitr::kable
kable(prob_matrix, caption = "The marginal distribution")
```
## Part d
The conditional probability distribution of \(Y\) given \(X\) is \(p_2(y|x) = \frac{p(x,y)}{p_1(x)}\). Since there are 3 levels of \(X\), there are 3 conditional distributions of \(Y\).

When \(X=1\), \(p_2(y|1)\) is given by:
\[
\begin{aligned}
p_2(1|1) &= \frac{p(1,1)}{p_1(1)} = \frac{1}{7} / \frac{1}{7} = 1 \\
p_2(2|1) &= \frac{p(1,2)}{p_1(1)} = 0 / \frac{1}{7} = 0 \\
p_2(3|1) &= \frac{p(1,3)}{p_1(1)} = 0 / \frac{1}{7} = 0
\end{aligned}
\]

The conditional probability distribution of \(Y\) given \(X=1\) is given in the table:
\[
\begin{array}{c|ccc}
y & 1 & 2 & 3 \\
\hline
p_2(y|1) & 1 & 0 & 0
\end{array}
\]

```{r}
library(knitr)

# Assuming you have the probabilities in a data frame already
prob_table <- data.frame(
  ` ` = c(1, 2, 3),
  `1` = c(1, 0, 0),
  `2` = c(0, 1, 0),
  `3` = c(0, 0, 1)
)

knitr::kable(prob_table, col.names = c("y", "p_2(y|1)", "p_2(y|2)", "p_2(y|3)"))
```

# Question 9
## Part a
\[
f_2(y) = \int_{y}^{2y} f(x,y) \, dx = \int_{y}^{2y} \frac{e^{-y/10}}{10y} \, dx = \left. \frac{e^{-y/10}}{10y} x \right|_{y}^{2y} = \frac{e^{-y/10}}{10y} (2y - y) = \frac{e^{-y/10}}{10}
\]

This is an exponential distribution with \( \beta = 10 \).

## Part b
The mean DOT estimate is $E(Y) = \mu = \beta = 10$.

# Question 10
## Part a
\[
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(x, y) \, dy \, dx = 1
\]
\[
\int_{0}^{\infty} \int_{0}^{x} ce^{-x^2} \, dy \, dx = \int_{0}^{\infty} ce^{-x^2} x \, dx = \int_{0}^{\infty} ce^{-x^2} (x - 0) \, dx
\]
\[
= \int_{0}^{\infty} cxe^{-x^2} \, dx = \left. -\frac{ce^{-x^2}}{2} \right|_{0}^{\infty} = -\left[ \frac{ce^{-\infty}}{2} - \frac{ce^{0}}{2} \right] = 0 + \frac{c}{2} = 1 \Rightarrow c = 2
\]

## Part b
\[
f_1(x) = \int_{-\infty}^{\infty} f(x,y) \, dy = \int_{0}^{x} 2e^{-x^2} \, dy = 2e^{-x^2} \left. y \right|_{0}^{x} = 2xe^{-x^2}
\]
\[
\int_{-\infty}^{\infty} f_1(x) \, dx = \int_{0}^{\infty} 2xe^{-x^2} \, dx = \left. -e^{-x^2} \right|_{0}^{\infty} = -e^{-\infty} + e^{0} = 0 + 1 = 1
\]

## Part c
\[
f_2(y|x) = \frac{f(x,y)}{f_1(x)} = \frac{2e^{-x^2}}{2xe^{-x^2}} = \frac{1}{x} \quad 0 \leq Y \leq x
\]

# Question 11
$$
Cov(X,Y) = E(XY) - E(X)E(Y)
$$
$$
E(XY) = \sum_x \sum_y xy p(x,y) = (-1)(-1)\left(\frac{1}{12}\right) + (-1)(0)\left(\frac{2}{12}\right) + (-1)(1)\left(\frac{1}{12}\right) + (0)(-1)\left(\frac{1}{12}\right) + (0)(0)\left(\frac{2}{12}\right) + (0)(1)\left(\frac{1}{12}\right) + (1)(-1)\left(\frac{1}{12}\right) + (1)(0)\left(\frac{2}{12}\right) + (1)(1)\left(\frac{1}{12}\right) = 0
$$
To find E(X) and E(Y), we must find the marginal distributions of X and Y.

$$
P(X = -1) = p_1(-1) = p(-1,-1) + p(-1,0) + p(-1,1) = \frac{1}{12} + \frac{2}{12} + \frac{1}{12} = \frac{1}{3}
$$
$$
P(X = 0) = p_1(0) = p(0,-1) + p(0,0) + p(0,1) = \frac{2}{12} + \frac{2}{12} + \frac{1}{12} = \frac{1}{3}
$$
$$
P(X = 1) = p_1(1) = p(1,-1) + p(1,0) + p(1,1) = \frac{1}{12} + \frac{2}{12} + \frac{1}{12} = \frac{1}{3}
$$
$$
E(X) = \sum_x xp_1(x) = (-1)\left(\frac{1}{3}\right) + (0)\left(\frac{1}{3}\right) + (1)\left(\frac{1}{3}\right) = 0
$$
$$
P(Y = -1) = p_2(-1) = p(-1,-1) + p(0,-1) + p(1,-1) = \frac{1}{12} + \frac{2}{12} + \frac{1}{12} = \frac{1}{3}
$$
$$
P(Y = 0) = p_2(0) = p(-1,0) + p(0,0) + p(1,0) = \frac{2}{12} + \frac{4}{12} + \frac{1}{12} = \frac{1}{3}
$$
$$
P(Y = 1) = p_2(1) = p(-1,1) + p(0,1) + p(1,1) = \frac{1}{12} + \frac{2}{12} + \frac{1}{12} = \frac{1}{3}
$$
$$
E(Y) = \sum_y yp_2(y) = (-1)\left(\frac{1}{3}\right) + (0)\left(\frac{1}{3}\right) + (1)\left(\frac{1}{3}\right) = 0
$$
$$
Cov(X,Y) = E(XY) - E(X)E(Y) = 0 - 0(0) = 0
$$
To show that X and Y are not independent, we must show that p(x,y) $\neq p_1(x)p_2(y)$ for at least one pair (x,y). Let x = -1 and y = -1.
$$
p(-1,-1) = \frac{1}{12}, \quad p_1(-1) = \frac{1}{3}, \quad \text{and} \quad p_2(-1) = \frac{1}{3}
$$
$$
p(x,y) = p_1(x)p_2(y) \Rightarrow \frac{1}{12} \neq \frac{1}{3} \left(\frac{1}{3}\right)
$$
Thus, X and Y are not independent even though Cov(X,Y) = 0.

# Question 12
$Y \sim U(1,3)$ Therefore, $E(Y) = \frac{1+3}{2} = 2$ and $V(Y) = \sigma^2_Y = \frac{(3-1)^2}{12} = \frac{4}{12} = \frac{1}{3}$. $n = 60$
## Part a
\[
E(\overline{Y}) = E\left(\frac{\sum_{i=1}^{60} Y_i}{n}\right) = \frac{1}{n} E\left(\sum_{i=1}^{60} Y_i\right) = \frac{1}{60} [60(2)] = 2
\]

## Part b
\[ 
\sigma^2_{\overline{Y}} = V(\overline{Y}) = V\left(\frac{\sum_{i=1}^{60} Y_i}{n}\right) = \left(\frac{1}{n}\right)^2 V\left(\sum_{i=1}^{60} Y_i\right) = \frac{1}{60^2} V\left(60\left(\frac{1}{3}\right)\right) = \frac{1}{60^2} \left[60\left(\frac{1}{3}\right)\right] = \frac{1}{180} = 0.00556 
\]

## Part c
By the Central Limit Theorem, the sampling distribution of \( \overline{Y} \) is approximately normal.

## Part d
\[
\sigma_{\overline{Y}} = \sqrt{0.00556} = 0.0745
\]

\[
P(1.5 \leq \overline{Y} \leq 2.5) = P\left(\frac{1.5 - 2}{0.0745} \leq Z \leq \frac{2.5 - 2}{0.0745}\right) = P(-6.71 \leq Z \leq 6.71)
\]

\[
= P(-6.71 \leq Z \leq 0) + P(0 \leq Z \leq 6.71) \approx 0.5 + 0.5 = 1
\]

## Part e
\[
P(\overline{Y} \geq 2.2) = P\left( Z \geq \frac{2.2 - 2}{0.0745} \right) = P(Z \geq 2.68)
\]

\[
= 0.5 - P(0 \leq Z \leq 2.68) = 0.5 + 0.4963 = 0.9963
\]

# Question 13
$Y \sim B(n, p) \sim B(20, 0.40) ; \quad \mu = np = 20(0.40) = 8 ; \quad \sigma = \sqrt{npq} = \sqrt{20(0.40)(0.60)} = \sqrt{4.8} = 2.1909$

## Part a
\[
P(Y < 2) = P\left( Z \leq \frac{1.5 - 8}{2.1909} \right) = P(Z \leq -2.97) = 0.5 - P(-2.97 \leq Z \leq 0) = 0.5 - 0.4985 = 0.0015
\]

## Part b
\[
P(Y > 10) = P\left( Z \geq \frac{10.5 - 8}{2.1909} \right) = P(Z \geq 1.14) = 0.5 - P(0 \leq Z < 1.14) = 0.5 - 0.3729 = 0.1271
\]

## Part c
\[
(Y \leq 2) = P(Y \leq 1) = 0.0005
\]

\[
P(Y > 10) = 1 - P(Y \leq 10) = 1 - 0.8725 = 0.1275
\]
The normal approximation provides a good estimate of the binomial distribution.

# Question 14
```{r}

```

## Part a
From the printout, the 99% confidence interval for the mean lead level in water specimens from Crystal Lake Manors is (-1.15, 6.92).

## Part b
From the printout, the 99% confidence interval for the mean copper level in water specimens from Crystal Lake Manors is (0.1519, 0.6647).

## Part c
We are 99% confident that the mean lead level in water specimens from Crystal Lake Manors is between -1.15 and 6.92. since the lead level cannot be negative, we are 99% confident that the mean lead level in water specimens from Crystal Lake Manors is between 0 and 6.92.

We are 99% confident that the mean lead level in water specimens from Crystal Lake Manors is between 0.1519 and 0.6647.

## Part d
99% confidence mean that in repeated sampling, 99% of all intervals constructed in a similiar manner will contain the true population mean.

# Question 15
For confidence coefficient 0.95, $\alpha = 0.05$ and $\alpha / 2 = 0.05 / 2 = 0.025$. From Table 7, Appendix B, $\nu = n - 1 = 7 - 1 = 6$ degrees of freedom, $t_{0.025} = 2.447$. The 95% confidence interval is:

\[
\bar{d} \pm t_{\alpha/2} \frac{S_d}{\sqrt{n}} = 198.0 \pm 2.447 \frac{44.5}{\sqrt{7}} \Rightarrow 198.0 \pm 41.16 \Rightarrow (156.84, 239.16)
\]

We are 95% confident that the true mean difference between the day-long clear-sky solar irradiation levels at the two sites is between 156.84 and 239.16.

# Question 16
## Part a
The differences are:

| Date | Day | Night | Diff |
|------|-----|-------|------|
| Jan 11 | 5.4 | 24.3 | -18.9 |
| Jan 12 | 2.7 | 16.5 | -13.8 |
| Jan 13 | 34.2| 47.2 | -13.0 |
| Jan 14 | 19.9| 12.4 |  7.5  |
| Jan 15 | 2.4 | 24.0 | -21.6 |
| Jan 16 | 7.0 | 21.6 | -14.6 |
| Jan 17 | 6.1 |104.3 | -98.2 |
| Jan 18 | 7.7 | 96.9 | -89.2 |
| Jan 19 | 18.4|105.3 | -86.9 |
| Jan 20 | 27.1| 78.7 | -51.6 |
| Jan 21 | 16.9| 44.6 | -27.7 |

\[
\bar{d} = \frac{\sum d_i}{n} = \frac{-428}{11} = 38.909; \quad s^2_d = \frac{\sum d^2_i - (\sum d_i)^2 / n}{n - 1} = \frac{30,033.96 - (-428)^2 / 11}{11 - 1} = 1,338.0869; \quad s_d = \sqrt{1,338.0869} = 36.5799
\]

Let $\mu_d$ = mean diazinon residue during the day and $\mu_n$ = mean diazinon residue at night. Then $\mu_d - \mu_n$ is the difference between the mean diazinon residue for day and night.

For confidence coefficient 0.90, $\alpha = 0.10$ and $\alpha / 2 = 0.10 / 2 = 0.05$. From Table 7, Appendix B, $\nu = n - 1 = 11 - 1 = 10$ degrees of freedom, $t_{0.05} = 1.812$. The 90% confidence interval is:

\[
\bar{d} \pm t_{\alpha/2} \frac{s_d}{\sqrt{n}} = -38.909 \pm 1.812 \frac{36.5799}{\sqrt{11}} = -38.909 \pm 19.985 \Rightarrow (-58.894, -18.924)
\]

We are 90% confident that the true mean difference between the day-long clear-sky solar irradiation levels at the two sites is between 156.84 and 239.16.

## Part b
We must assume the population of differences is normal

## Part c
The confidence interval calculated in the previous section does not encompass the value zero, indicating statistically significant evidence of a disparity in mean diazinon residues between daytime and nighttime measurements. Furthermore, as the interval exclusively consists of negative values, it can be inferred that the mean diazinon residue during nighttime is statistically higher than that during the daytime.